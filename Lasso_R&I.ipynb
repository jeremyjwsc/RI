{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso (coordinate descent) - Carlos and Jeremy - R&I "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will:\n",
    "* Develop a function to normalize features and implement coordinate descent for LASSO \n",
    "* Study the L1 penalty (regularization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, \n",
    "              'sqft_above':int, 'sqft_living15':float, \n",
    "              'grade':int, 'yr_renovated':int, 'price':float,\n",
    "              'bedrooms':float, 'zipcode':str, 'long':float, \n",
    "              'sqft_lot15':float, 'sqft_living':float, 'floors':str, \n",
    "              'condition':int, 'lat':float, 'date':str, \n",
    "              'sqft_basement':int, 'yr_built':int, 'id':str,\n",
    "              'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the house sales dataset\n",
    "\n",
    "Dataset is from house sales in King County, \n",
    "the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('kc_house_data.csv',dtype=dtype_dict)\n",
    "sales['floors'] = sales['floors'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                object\n",
       "date              object\n",
       "price            float64\n",
       "bedrooms         float64\n",
       "bathrooms        float64\n",
       "sqft_living      float64\n",
       "sqft_lot           int32\n",
       "floors             int32\n",
       "waterfront         int32\n",
       "view               int32\n",
       "condition          int32\n",
       "grade              int32\n",
       "sqft_above         int32\n",
       "sqft_basement      int32\n",
       "yr_built           int32\n",
       "yr_renovated       int32\n",
       "zipcode           object\n",
       "lat              float64\n",
       "long             float64\n",
       "sqft_living15    float64\n",
       "sqft_lot15       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot House Prices from the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa0ac0b8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['price'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list \n",
    "    # so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list \n",
    "    # into the SFrame features_sframe (now including constant):\n",
    "    features_sframe = data_sframe[features]\n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.as_matrix()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_sarray = data_sframe[output]\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_sarray.as_matrix()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict_output()` function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing \n",
    "    # the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix,weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize features\n",
    "\n",
    "We now **normalize features** by dividing each feature by its 2-norm so that the transformed feature has norm 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can do this normalization easily with Numpy: let us first consider a small matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20. 24. 40.]\n",
      " [22. 28. 44.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[20.,24.,40.],[22.,28.,44.]])\n",
    "print X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.73213749 36.87817783 59.46427499]\n"
     ]
    }
   ],
   "source": [
    "norms = np.linalg.norm(X, axis=0) # gives [norm(X[:,0]), norm(X[:,1]), norm(X[:,2])]\n",
    "print norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To normalize, apply element-wise division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67267279 0.65079137 0.67267279]\n",
      " [0.73994007 0.7592566  0.73994007]]\n"
     ]
    }
   ],
   "source": [
    "print X / norms # gives [X[:,0]/norm(X[:,0]), X[:,1]/norm(X[:,1]), X[:,2]/norm(X[:,2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use these norms to normalize the test data in the same way as we normalized the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix,axis = 0)\n",
    "    normalized_features = feature_matrix/norms\n",
    "    return normalized_features,norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now testing the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [[0.67267279 0.65079137 0.67267279]\n",
      " [0.73994007 0.7592566  0.73994007]]\n"
     ]
    }
   ],
   "source": [
    "features, norms = normalize_features(np.array([[20.,24.,40.],[22.,28.,44.]]))\n",
    "print \"Features: \" + str(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norms: [29.73213749 36.87817783 59.46427499]\n"
     ]
    }
   ],
   "source": [
    "print \"Norms: \" + str(norms) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing the coordinate descent with normalized features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to minimize the LASSO cost function\n",
    "```\n",
    "SUM[ (prediction - output)^2 ] + lambda*( |wt[1]| + ... + |wt[k]|).\n",
    "```\n",
    "We do not want to push the intercept to zero so, `wt[0]` is not included in the L1 penalty term.\n",
    "\n",
    "The **coordinate descent** will be used at each iteration \n",
    "\n",
    "We will fix all weights but weight `i` \n",
    "\n",
    "Then find the value of weight `i` that minimizes the objective. \n",
    "\n",
    "In other words, we seek:\n",
    "```\n",
    "argmin_{wt[i]} [ SUM[ (prediction - output)^2 ] + lambda*( |wt[1]| + ... + |wt[k]|) ]\n",
    "```\n",
    "where all weights other than `wt[i]` are held to be constant. \n",
    "\n",
    "We will also optimize one `wt[i]` at a time, and move through the computation with the weights multiple times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this process:\n",
    "\n",
    "We use the **cyclical coordinate descent with normalized features**, \n",
    "where we cycle through coordinates 0 to (d-1) in order, \n",
    "and assume the features were normalized as discussed above. \n",
    "\n",
    "We optimize each coordinate using the following formula:\n",
    "```\n",
    "       ┌ (Zo[i] + lambda/2)     if Zo[i] < -lambda/2\n",
    "wt[i] = ├ 0                      if -lambda/2 <= Zo[i] <= lambda/2\n",
    "       └ (Zo[i] - lambda/2)     if Zo[i] > lambda/2\n",
    "```\n",
    "where\n",
    "```\n",
    "Zo[i] = SUM[ [feature_i]*(output - prediction + wt[i]*[feature_i]) ].\n",
    "```\n",
    "\n",
    "We do no regularize the weight of the constant feature (intercept) `wt[0]`.\n",
    "\n",
    "With that said, we updated with:\n",
    "```\n",
    "wt[0] = Zo[i]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying the L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a simple model with 2 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ML1_features = ['sqft_living', 'bedrooms']\n",
    "ML1_output = 'price'\n",
    "(ML1_feature_matrix, output) = get_numpy_data(sales, ML1_features, ML1_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML1_feature_matrix, norms = normalize_features(ML1_feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign some random set of initial weights and inspect the values of `Zo[i]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([2., 8., 6.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `predict_output()` to make predictions on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_output(ML1_feature_matrix,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the values of `Zo[i]` for each feature in this simple model:\n",
    "```\n",
    "Zo[i] = SUM[ [feature_i]*(output - prediction + wt[i]*[feature_i]) ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 8. 6.]\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[79400291.53547528, 87939465.18951182, 80966693.92709385]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zo = list()\n",
    "print weights\n",
    "for i in range(0,len(ML1_features)+1):\n",
    "    print i\n",
    "    feature_i = ML1_feature_matrix[:,i]\n",
    "    Zo.append( sum((feature_i)*(output - prediction + weights[i]*feature_i) ))\n",
    "Zo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Coordinate Descent Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now minimize the cost function over a single feature `i` \n",
    "with the coordinate descent step. \n",
    "\n",
    "To optimize over, the function should accept **feature matrix, \n",
    "output, current weights, l1 penalty and index of the feature**. \n",
    "\n",
    "And the function should return new weight for feature `i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty):\n",
    "    # compute prediction\n",
    "    prediction = predict_output(feature_matrix,weights)\n",
    "    # compute Zo[i] = SUM[ [feature_i]*(output - prediction + weight[i]*[feature_i]) ]\n",
    "    feature_i = feature_matrix[:,i]\n",
    "    Zo_i = sum((feature_i)*(output - prediction + weights[i]*feature_i) )\n",
    "\n",
    "    if i == 0: # intercept -- do not regularize\n",
    "        new_weight_i = Zo_i \n",
    "    elif Zo_i < -l1_penalty/2.:\n",
    "        new_weight_i = Zo_i + l1_penalty/2\n",
    "    elif Zo_i > l1_penalty/2.:\n",
    "        new_weight_i = Zo_i - l1_penalty/2\n",
    "    else:\n",
    "        new_weight_i = 0.\n",
    "    \n",
    "    return new_weight_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4255588466910251\n"
     ]
    }
   ],
   "source": [
    "# We should print 0.425558846691\n",
    "import math\n",
    "print lasso_coordinate_descent_step(1, np.array([[3./math.sqrt(13),1./math.sqrt(10)],\n",
    "                                                 [2./math.sqrt(13),3./math.sqrt(10)]]), \n",
    "                                                 np.array([1., 1.]), np.array([1., 4.]), 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cyclical coordinate descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement a cyclical coordinate descent where we optimize coordinates 0, 1, ..., (d-1) in order and repeat. \n",
    "\n",
    "We will measure the change in weight for each coordinate. \n",
    "\n",
    "If no coordinate changes by more than a specified threshold, we stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each iteration:\n",
    "* As we loop over features in order and perform coordinate descent, measure how much each coordinate changes.\n",
    "\n",
    "* After the loop, if the maximum change across all coordinates is falls below the tolerance, stop. \n",
    "\n",
    "* Otherwise, go back to step 1.\n",
    "\n",
    "Return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_cyclical_coordinate_descent(feature_matrix, output, \n",
    "                                      initial_weights, l1_penalty, \n",
    "                                      tolerance):\n",
    "    while True:\n",
    "        maxstep = -1\n",
    "        maxi = 0\n",
    "        weights = np.zeros(len(initial_weights))\n",
    "        for i in range(len(initial_weights)):\n",
    "            weights[i] = lasso_coordinate_descent_step(i,feature_matrix,\n",
    "                                                       output,initial_weights,\n",
    "                                                       l1_penalty)\n",
    "            step = abs(weights[i]-initial_weights[i])\n",
    "            if(step>maxstep):\n",
    "                maxstep = step\n",
    "                maxi = i          \n",
    "        initial_weights[maxi]=weights[maxi]\n",
    "        #print maxi,maxstep\n",
    "        if maxstep < tolerance:\n",
    "            return initial_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following parameters, learn the weights on the sales dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                object\n",
       "date              object\n",
       "price            float64\n",
       "bedrooms         float64\n",
       "bathrooms        float64\n",
       "sqft_living      float64\n",
       "sqft_lot           int32\n",
       "floors             int32\n",
       "waterfront         int32\n",
       "view               int32\n",
       "condition          int32\n",
       "grade              int32\n",
       "sqft_above         int32\n",
       "sqft_basement      int32\n",
       "yr_built           int32\n",
       "yr_renovated       int32\n",
       "zipcode           object\n",
       "lat              float64\n",
       "long             float64\n",
       "sqft_living15    float64\n",
       "sqft_lot15       float64\n",
       "constant           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML1_features = ['sqft_living', 'sqft_living15']\n",
    "ML1_output = 'price'\n",
    "initial_weights = np.zeros(3)\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalized the feature matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "(ML1_feature_matrix, output) = get_numpy_data(sales, \n",
    "                                              ML1_features, ML1_output)\n",
    "(normalized_ML1_feature_matrix, ML1_norms) = normalize_features(ML1_feature_matrix) # normalize features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we execute the LASSO coordinate descent implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS: 1630492383845787.8\n",
      "Weights: [21624988.74465544 63157256.49484932        0.        ]\n"
     ]
    }
   ],
   "source": [
    "weights = lasso_cyclical_coordinate_descent(normalized_ML1_feature_matrix, output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "RSS = sum((predict_output(normalized_ML1_feature_matrix,weights)-output)**2)\n",
    "print 'RSS: ' + str(RSS)\n",
    "print 'Weights: ' + str(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study the LASSO fit with more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the sales dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('kc_house_train_data.csv',dtype=dtype_dict)\n",
    "test_data = pd.read_csv('kc_house_test_data.csv',dtype=dtype_dict)\n",
    "train_data['floors'] = train_data['floors'].astype(float).astype(int)\n",
    "test_data['floors'] = test_data['floors'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the following set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_features = ['bedrooms',\n",
    "                'bathrooms',\n",
    "                'sqft_living',\n",
    "                'sqft_lot',\n",
    "                'floors',\n",
    "                'waterfront', \n",
    "                'view', \n",
    "                'condition', \n",
    "                'grade',\n",
    "                'sqft_above',\n",
    "                'sqft_basement',\n",
    "                'yr_built', \n",
    "                'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the feature matrix from the TRAINING data with these features:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "(feature_matrix, output) = get_numpy_data(train_data, \n",
    "                                          more_features, 'price')\n",
    "normalized_training,norms = normalize_features(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we learn the weights with `l1_penalty=1e7`, on the training data. \n",
    "\n",
    "Initialize weights to all zeros, and set the `tolerance=1`.  \n",
    "\n",
    "Call resulting weights `wts_1e7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = np.zeros(14)\n",
    "wts_1e7 = lasso_cyclical_coordinate_descent(normalized_training, output,\n",
    "                                            initial_weights, 1e7, 1)\n",
    "a7 = wts_1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24429589.93019406,        0.        ,        0.        ,\n",
       "       48389184.67771954,        0.        ,        0.        ,\n",
       "        3317511.59607863,  7329960.45195356,        0.        ,\n",
       "              0.        ,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24429589.93019406        0.                0.         48389184.67771954\n",
      "        0.                0.          3317511.59607863  7329960.45195356\n",
      "        0.                0.                0.                0.\n",
      "        0.                0.        ]\n",
      "0 constant\n",
      "3 sqft_living\n",
      "6 waterfront\n",
      "7 view\n"
     ]
    }
   ],
   "source": [
    "print wts_1e7\n",
    "for i in range(0,len(wts_1e7)):\n",
    "    if wts_1e7[i]!=0 and i==0:\n",
    "        print 0,'constant'\n",
    "    elif wts_1e7[i]!=0:\n",
    "        print i,more_features[i-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we learn the weights with `l1_penalty=1e8`, on the training data. \n",
    "\n",
    "Initialize weights to all zeros, and set the `tolerance=1`.  \n",
    "\n",
    "Call resulting weights `wts_1e8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 constant\n"
     ]
    }
   ],
   "source": [
    "initial_weights = np.zeros(14)\n",
    "wts_1e8 = lasso_cyclical_coordinate_descent(normalized_training, output,\n",
    "                                            initial_weights, 1e8, 1)\n",
    "\n",
    "for i in range(0,len(wts_1e8)):\n",
    "    if wts_1e8[i]!=0:\n",
    "        if i == 0:\n",
    "            print 0,'constant'\n",
    "        else:\n",
    "            print i,more_features[i-1]\n",
    "a8 = wts_1e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we learn the weights with `l1_penalty=1e4`, on the training data. \n",
    "\n",
    "Initialize weights to all zeros, and set the `tolerance=5e5`.  \n",
    "\n",
    "Call resulting weights `wts_1e4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bedrooms\n",
      "3 sqft_living\n",
      "4 sqft_lot\n",
      "5 floors\n",
      "6 waterfront\n",
      "7 view\n",
      "8 condition\n",
      "9 grade\n",
      "12 yr_built\n",
      "13 yr_renovated\n"
     ]
    }
   ],
   "source": [
    "initial_weights = np.zeros(14)\n",
    "wts_1e4 = lasso_cyclical_coordinate_descent(normalized_training, output,\n",
    "                                            initial_weights, 1e4, 5e5)\n",
    "for i in range(0,len(wts_1e4)):\n",
    "    if wts_1e4[i]!=0:\n",
    "        if i ==0:\n",
    "            print 0,'constant'\n",
    "        else:\n",
    "            print i,more_features[i-1]\n",
    "a4 = wts_1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling learned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rescale the learned weights to include the normalization.\n",
    "\n",
    "This will help us to not worry about normalizing the test data: \n",
    "\n",
    "With that said, we will scale our weights to make predictions with **original** features:\n",
    "```\n",
    "features, norms = normalize_features(features)\n",
    "weights_normalized = weights / norms\n",
    "```\n",
    "Now, we can use the test data, without normalizing it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply to the weights learned above. (`wt_1e4`, `wt_1e7`, `wt_1e8`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features, norms = normalize_features(more_features)\n",
    "normalized_wt_1e4=a4/norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_wt_1e7=a7/norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_wt_1e8=a8/norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your results, if you call `normalized_wt_1e7` the normalized version of `wt_1e7`, then:\n",
    "```\n",
    "print normalized_wt_1e7[3]\n",
    "```\n",
    "should return 161.31745624837794."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161.31749067082325\n"
     ]
    }
   ],
   "source": [
    "print normalized_wt_1e7[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the learned models on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now evaluate the three models on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "(ML1_feature_matrix, ML1_output) = get_numpy_data(test_data, \n",
    "                                                  more_features, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSS for all three normalized weights on the (unnormalized) `ML1_feature_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSS_wt_4 = sum((predict_output(ML1_feature_matrix,\n",
    "                               normalized_wt_1e4)-ML1_output)**2)\n",
    "RSS_wt_7 = sum((predict_output(ML1_feature_matrix,\n",
    "                               normalized_wt_1e7)-ML1_output)**2)\n",
    "RSS_wt_8 = sum((predict_output(ML1_feature_matrix,\n",
    "                               normalized_wt_1e8)-ML1_output)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS for wt_1e4: 225789014748755.2\n",
      "RSS for wt_1e7: 275962057997703.12\n",
      "RSS for wt_1e8: 537166151497322.4\n"
     ]
    }
   ],
   "source": [
    "print 'RSS for wt_1e4: ' + str(RSS_wt_4)\n",
    "print 'RSS for wt_1e7: ' + str(RSS_wt_7)\n",
    "print 'RSS for wt_1e8: ' + str(RSS_wt_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
